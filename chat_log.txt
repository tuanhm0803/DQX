Conversation Log - DQX Project Refactoring (June 2025)

TASK DESCRIPTION:
Refactor the DQX FastAPI project to use `psycopg2` instead of SQLAlchemy for all database interactions. This includes ensuring all endpoints and CRUD operations work with the new approach, resolving any related errors, updating documentation, removing the "Secure Execution" feature from the homepage (`index.html`), and maintaining a detailed log of all changes and discussions.

SUMMARY OF ACTIONS AND RESOLUTIONS:

1.  **Initial Refactoring (SQLAlchemy to psycopg2):**
    *   Replaced all SQLAlchemy session and ORM logic with direct `psycopg2` connections and queries in `app/database.py`, `app/crud.py`, and all route files (`app/routes/*.py`).
    *   Updated FastAPI's dependency injection (`Depends(get_db)`) to provide a `psycopg2` connection object.
    *   Rewrote CRUD functions to use `psycopg2.sql` for safe dynamic table/column identifiers and parameterized queries for values, preventing SQL injection.
    *   Implemented robust transaction management with explicit `db.commit()` and `db.rollback()` in `try...except` blocks.

2.  **Documentation and Git Sync:**
    *   Updated `DOCUMENTATION.md` to reflect the architectural shift from SQLAlchemy to `psycopg2`.
    *   Created this `chat_log.txt` file to maintain a record of the process.
    *   Staged, committed, and pushed all initial changes to the remote Git repository.

3.  **Frontend Error Resolution - "scripts.forEach is not a function":**
    *   **Problem:** The frontend failed to load scripts because the backend API was returning an error object (e.g., `{"detail": "..."}`) instead of the expected array of scripts.
    *   **Cause:** This was traced to the `dq.dq_sql_scripts` table not existing in the database, causing the `get_sql_scripts` function to fail.
    *   **Resolution:** Provided the correct DDL for the user to create the `dq.dq_sql_scripts` table in their PostgreSQL database.

4.  **Frontend Error Resolution - "Unexpected token 'I', 'Internal S'... is not valid JSON":**
    *   **Problem:** When loading the SQL Editor page, the frontend JavaScript failed because it received an HTML error page from the server instead of a JSON response.
    *   **Cause:** An unhandled exception was occurring in the FastAPI backend, causing the server (Uvicorn) to return its default HTML error page.
    *   **Resolution (Part 1 - Frontend Resilience):**
        *   Modified `app/static/sql_editor.html` by adding a centralized `handleResponse` JavaScript function.
        *   This function now checks if `response.ok` is true. If not, it safely reads the response as text and displays a proper error message to the user, whether the error is in JSON format or plain text/HTML.
        *   Applied this handler to all `fetch()` calls.
    *   **Resolution (Part 2 - Backend JSON Enforcement):**
        *   Modified `app/main.py` to include a global exception handler (`@app.exception_handler(Exception)`).
        *   This handler catches any unhandled exception in the application and guarantees that a `JSONResponse` with a `500` status code and error details is always returned.

5.  **Pydantic Validation Error - "Input should be a valid integer" for `id`:**
    *   **Problem:** After the previous fix, a new, correctly formatted JSON error appeared, indicating a Pydantic validation failure. The `/scripts/` endpoint was returning a script object where the `id` field was `null`.
    *   **Cause:** A row existed in the `dq.dq_sql_scripts` database table with a `NULL` value in the `id` primary key column. Pydantic's `SQLScript` model correctly rejected this as it requires an integer.
    *   **Resolution (Backend `crud.py`):**
        *   Updated the `get_sql_scripts` function in `app/crud.py`.
        *   The function now fetches all rows, iterates through them, and explicitly checks if the `id` for any given row is `None`.
        *   If an `id` is `None`, it prints a warning to the server console (for debugging and data cleanup) and skips that record, ensuring only valid data is sent to the frontend.
        *   This resolved the validation error and allowed the script list to load correctly.

6.  **Final Cleanup:**
    *   Removed the "Secure Execution" feature/section from `app/static/index.html` as requested.
    *   Addressed minor linter warnings (e.g., unused variables) in `app/crud.py`.

7.  **SQL Script Validation Logic:**
    *   **Requirement:** Implemented a strict validation rule for all SQL scripts. Scripts must be `SELECT` statements and must contain exactly five specific columns: `rule_id`, `source_id`, `source_uid`, `data_value`, and `txn_date`.
    *   **Implementation (`app/crud.py`):
        *   Created a new private function, `_validate_sql_script_columns`, which uses a regular expression to parse the SQL content.
        *   This function verifies that the script starts with `SELECT` and that the columns between the `SELECT` and `FROM` keywords match the required set exactly.
        *   It raises a `ValueError` with a detailed message if the script is not a `SELECT` statement, has missing columns, or includes extra, disallowed columns.
    *   **Integration:**
        *   The `_validate_sql_script_columns` function is now called at the beginning of `create_sql_script`, `update_sql_script`, and `execute_sql_script`.
        *   This ensures that no invalid script can be saved to the database or executed, enforcing the required data structure at the application level.
    *   **Error Handling:** The `ValueError` from the validation function is caught in the API route handlers (`app/routes/sql_scripts.py`), which then return a `400 Bad Request` HTTP response with a clear error message to the user, explaining why their script was rejected.

8.  **SQL Script Validation Fix (No 'FROM' clause):**
    *   **Problem:** The SQL validation logic incorrectly rejected valid `SELECT` statements that did not contain a `FROM` clause (e.g., `SELECT 'a' as rule_id, ...`).
    *   **Cause:** The regular expression used to extract the column list required a `FROM` clause to be present.
    *   **Resolution (`app/crud.py`):**
        *   Modified the `_validate_sql_script_columns` function.
        *   The logic now first checks for the presence of a `FROM` clause.
        *   If `FROM` exists, it extracts the column list between `SELECT` and `FROM`.
        *   If `FROM` does not exist, it treats the entire string after `SELECT` as the column list.
        *   This ensures that `SELECT` statements with literal values are correctly validated.

9.  **Staging and Publishing Feature:**
    *   **Requirement:** Add a feature to first load script results into a temporary staging table for review, and then "publish" those results to a final `dq.bad_detail` table.
    *   **Implementation (`app/crud.py`):
        *   `create_sql_script`: Now also creates a corresponding staging table `stg.dq_script_{id}` with the same structure as the script's output, but with no data.
        *   `delete_sql_script`: Now also drops the corresponding staging table.
        *   `populate_script_result_table`: A new function that truncates the staging table and inserts the results from running the associated SQL script.
        *   `publish_script_results`: A new function that copies data from the staging table to `dq.bad_detail`. It first deletes old records for the script's `rule_id` before inserting the new ones, ensuring the operation is idempotent.
    *   **Implementation (`app/routes/sql_scripts.py`):
        *   Added a `POST /{script_id}/populate_table` endpoint to trigger `populate_script_result_table`.
        *   Added a `POST /{script_id}/publish` endpoint to trigger `publish_script_results`.
    *   **Implementation (`app/static/sql_editor.html`):
        *   Added a "Populate" button for each script to call the populate endpoint.
        *   Added a "Publish" button for each script to call the publish endpoint.
    *   **Documentation:** Updated `DOCUMENTATION.md` to reflect the new staging/publishing workflow, API endpoints, and required table schemas (`dq.bad_detail`).

10. **Publishing Logic Enhancement (Composite Keys):**
    *   **Problem:** The initial publishing logic deleted all records from `dq.bad_detail` associated with a single `rule_id` from the script. This was incorrect if a script produced data for multiple `(rule_id, source_id)` pairs, as it would delete valid data for pairs not present in the current staging table.
    *   **Resolution (`app/crud.py`):
        *   Modified the `publish_script_results` function.
        *   The function now first queries the staging table to find all unique `(rule_id, source_id)` pairs.
        *   It then deletes records from `dq.bad_detail` only for those specific pairs.
        *   Finally, it inserts all records from the staging table into `dq.bad_detail`.
        *   This ensures that the publishing action for a script only affects the specific `(rule_id, source_id)` combinations that the script is responsible for, making the process more precise and safe.
    *   **Documentation:** Updated `DOCUMENTATION.md` and `chat_log.txt` to reflect the improved composite key logic in the publishing feature.

11. **Unique Script Name Enforcement:**
    *   **Requirement:** Prevent users from creating multiple SQL scripts with the same name.
    *   **Implementation (`app/crud.py`):
        *   Modified `create_sql_script` to check if a script with the given name already exists before inserting a new record.
        *   Modified `update_sql_script` to check if another script (with a different ID) already has the target name before applying the update.
    *   **Error Handling:** If a duplicate name is detected, a `ValueError` is raised, which results in a `400 Bad Request` response with a clear error message to the user.

12. **Scheduler Feature and UI Overhaul:**
    *   **Requirement:** Introduce a new feature to schedule SQL scripts to run at specified intervals (daily, weekly, monthly) and refactor the frontend for a more modern and consistent look and feel.
    *   **Implementation (Backend):
        *   Created a new `dq.dq_schedules` table to store schedule information.
        *   Added `create_schedule`, `get_schedules`, `update_schedule`, and `delete_schedule` functions to `app/crud.py`.
        *   Added a new `app/routes/scheduler.py` with API endpoints to manage schedules.
        *   Integrated the scheduler router into `app/main.py`.
    *   **Implementation (Frontend):
        *   Created a new `app/static/scheduler.html` page with a UI for creating and viewing schedules.
        *   Refactored the CSS by creating a shared `app/static/css/style.css` file and linking it from all HTML pages (`index.html`, `sql_editor.html`, `bad_detail_query.html`, `scheduler.html`).
        *   Updated `index.html` with a new "Job Scheduler" card and a more modern design.
    *   **Fixes:**
        *   Resolved an issue where the stats on the main page were not displaying correctly by improving the JavaScript fetch logic in `index.html`.
